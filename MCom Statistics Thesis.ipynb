{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1a1c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (C:\\Users\\Jean-Pierre\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb53ac99fb1145d5aa1eaf578567872f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\Jean-Pierre\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4649773e11c40eea21462b148b41c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
      "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
      "2  If only to avoid making this type of film in t...      0\n",
      "3  This film was probably inspired by Godard's Ma...      0\n",
      "4  Oh, brother...after hearing about this ridicul...      0\n",
      "                                                text  label\n",
      "0  I love sci-fi and am willing to put up with a ...      0\n",
      "1  Worth the entertainment value of a rental, esp...      0\n",
      "2  its a totally average film with a few semi-alr...      0\n",
      "3  STAR RATING: ***** Saturday Night **** Friday ...      0\n",
      "4  First off let me say, If you haven't enjoyed a...      0\n",
      "                                                text  label\n",
      "0  Wall St. Bears Claw Back Into the Black (Reute...      2\n",
      "1  Carlyle Looks Toward Commercial Aerospace (Reu...      2\n",
      "2  Oil and Economy Cloud Stocks' Outlook (Reuters...      2\n",
      "3  Iraq Halts Oil Exports from Main Southern Pipe...      2\n",
      "4  Oil prices soar to all-time record, posing new...      2\n",
      "                                                text  label\n",
      "0  Fears for T N pension after talks Unions repre...      2\n",
      "1  The Race is On: Second Private Team Sets Launc...      3\n",
      "2  Ky. Company Wins Grant to Study Peptides (AP) ...      3\n",
      "3  Prediction Unit Helps Forecast Wildfires (AP) ...      3\n",
      "4  Calif. Aims to Limit Farm-Related Smog (AP) AP...      3\n"
     ]
    }
   ],
   "source": [
    "# Import the IMDb and AG News datasets from Hugging Face and storing them as pandas dataframes\n",
    "from datasets import load_dataset # IMDB and AG News datasets\n",
    "import pandas as pd # pandas dataframes\n",
    "import numpy as np # obtaining accuracy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "imdb_dataset = load_dataset(\"imdb\")\n",
    "imdb_train = pd.DataFrame(imdb_dataset['train'])\n",
    "imdb_test = pd.DataFrame(imdb_dataset['test'])\n",
    "ag_news_dataset = load_dataset(\"ag_news\")\n",
    "ag_news_train = pd.DataFrame(ag_news_dataset['train'])\n",
    "ag_news_test = pd.DataFrame(ag_news_dataset['test'])\n",
    "\n",
    "# Illustrating the first 5 observations in the training and test sets\n",
    "print(imdb_train.head())\n",
    "print(imdb_test.head())\n",
    "print(ag_news_train.head())\n",
    "print(ag_news_test.head())\n",
    "\n",
    "# Generating a sample of observations from each dataset\n",
    "# Can remove later\n",
    "imdb_train = imdb_train.groupby('label').apply(lambda x: x.sample(1000, random_state=123))\n",
    "imdb_test = imdb_test.groupby('label').apply(lambda x: x.sample(1000, random_state=123))\n",
    "ag_news_train = ag_news_train.groupby('label').apply(lambda x: x.sample(1000, random_state=123))\n",
    "ag_news_test = ag_news_test.groupby('label').apply(lambda x: x.sample(1000, random_state=123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ad394e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                          text  label\n",
      "label                                                                \n",
      "0     9271   Half Past Dead, starring Steven Seagal in the ...      0\n",
      "      7395   Being a Film studies graduate I would like to ...      0\n",
      "      793    Towards the end of this thriller Ally Sheedy's...      0\n",
      "      9374   this movie was banned in england? why? tom sav...      0\n",
      "      10712  The movie was not a waste except for some bori...      0\n",
      "                                                          text  label\n",
      "label                                                                \n",
      "0     9271   It is not uncommon for a celebrity to be faced...      0\n",
      "      7395   I like Kevin Bacon and Cathy Moriarty, and I l...      0\n",
      "      793    Every great romantic comedy needs conflict bet...      0\n",
      "      9374   This film has absolutely no redeeming features...      0\n",
      "      10712  As a nice anecdote to one of the above comment...      0\n",
      "                                                           text  label\n",
      "label                                                                 \n",
      "0     101910  8 Slashed to Death in Chinese High School The ...      0\n",
      "      63719   Palestinians in plea to UK over peace process ...      0\n",
      "      88643   China mine blast toll rises to 33 as inspectio...      0\n",
      "      38714   Sniper Said to Admit Guilt in 2nd Slaying McLE...      0\n",
      "      32985   Bush, Kerry Tentatively OK Three Debates NEW Y...      0\n",
      "                                                         text  label\n",
      "label                                                               \n",
      "0     4044  Australian journalist tells of capture in Iraq...      0\n",
      "      5286  Negotiations for hostages in Afghanistan fall ...      0\n",
      "      7032  U.S. Alone Among Allies in Centralizing Spy Po...      0\n",
      "      1222  Anwar launches bid to clear name Lawyers for A...      0\n",
      "      7519  Saddam meets lawyer, aides due in Court Saddam...      0\n"
     ]
    }
   ],
   "source": [
    "print(imdb_train.head())\n",
    "print(imdb_test.head())\n",
    "print(ag_news_train.head())\n",
    "print(ag_news_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49541e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the document-term matrices\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "imdb_train_docs = imdb_train['text'].tolist()\n",
    "vectoriser = CountVectorizer()\n",
    "imdb_train_dtm = vectoriser.fit_transform(imdb_train_docs)\n",
    "imdb_train_dtm = pd.DataFrame(imdb_train_dtm.toarray(), columns=vectoriser.get_feature_names())\n",
    "imdb_test_docs = imdb_test['text'].tolist()\n",
    "imdb_test_dtm = vectoriser.transform(imdb_test_docs)\n",
    "imdb_test_dtm = pd.DataFrame(imdb_test_dtm.toarray(), columns=vectoriser.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d8ba43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[603, 397],\n",
       "       [428, 572]], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "imdb_nb = nb.fit(imdb_train_dtm, imdb_train['label'].tolist())\n",
    "imdb_nb_preds = imdb_nb.predict(imdb_test_dtm)\n",
    "print(np.mean(imdb_nb_preds == imdb_test['label'].tolist()))\n",
    "confusion_matrix(imdb_test['label'].tolist(), imdb_nb_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27f64652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[827, 173],\n",
       "       [173, 827]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(solver = 'liblinear')\n",
    "imdb_logreg = logreg.fit(imdb_train_dtm, imdb_train['label'].tolist())\n",
    "imdb_logreg_preds = imdb_logreg.predict(imdb_test_dtm)\n",
    "print(np.mean(imdb_logreg_preds == imdb_test['label'].tolist()))\n",
    "confusion_matrix(imdb_test['label'].tolist(), imdb_logreg_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1eb9485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[846, 154],\n",
       "       [197, 803]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "svm = SGDClassifier(random_state=123)\n",
    "imdb_svm = svm.fit(imdb_train_dtm, imdb_train['label'].tolist())\n",
    "imdb_svm_preds = imdb_svm.predict(imdb_test_dtm)\n",
    "print(np.mean(imdb_svm_preds == imdb_test['label'].tolist()))\n",
    "confusion_matrix(imdb_test['label'].tolist(), imdb_svm_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ef57693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[810, 190],\n",
       "       [181, 819]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=123)\n",
    "imdb_rf = rf.fit(imdb_train_dtm, imdb_train['label'].tolist())\n",
    "imdb_rf_preds = imdb_rf.predict(imdb_test_dtm)\n",
    "print(np.mean(imdb_rf_preds == imdb_test['label'].tolist()))\n",
    "confusion_matrix(imdb_test['label'].tolist(), imdb_rf_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
