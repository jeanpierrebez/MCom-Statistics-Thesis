{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loVnbXBNJJul"
      },
      "outputs": [],
      "source": [
        "# Installing the required dependencies\n",
        "!pip install datasets\n",
        "!pip install nltk\n",
        "!pip install bs4\n",
        "!pip install gensim\n",
        "!pip install nlpaug"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading in the required libraries\n",
        "from datasets import load_dataset\n",
        "import random\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import tqdm as tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "cm-NjB04JxxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the IMDb dataset from Hugging Face and creating the different splits\n",
        "imdb_dataset = load_dataset(\"imdb\")\n",
        "imdb_train = imdb_dataset[\"train\"][\"text\"]\n",
        "imdb_train_y = np.array(imdb_dataset[\"train\"][\"label\"])\n",
        "imdb_test = imdb_dataset[\"test\"][\"text\"]\n",
        "imdb_test_y = np.array(imdb_dataset[\"test\"][\"label\"])"
      ],
      "metadata": {
        "id": "RlbOQrkLKNFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing our training data\n",
        "stopwords_list = stopwords.words(\"english\")\n",
        "processed_reviews_train = []\n",
        "for review in tqdm.tqdm(imdb_train):\n",
        "  raw = BeautifulSoup(review)\n",
        "  html_remove = raw.get_text()\n",
        "  temp = simple_preprocess(html_remove)\n",
        "  temp_update = [x for x in temp if x not in stopwords_list]\n",
        "  processed_reviews_train.append(temp_update)\n",
        "\n",
        "# Preprocessing our testing data\n",
        "stopwords_list = stopwords.words(\"english\")\n",
        "processed_reviews_test = []\n",
        "for review in tqdm.tqdm(imdb_test):\n",
        "  raw = BeautifulSoup(review)\n",
        "  html_remove = raw.get_text()\n",
        "  temp = simple_preprocess(html_remove)\n",
        "  temp_update = [x for x in temp if x not in stopwords_list]\n",
        "  processed_reviews_test.append(temp_update)\n",
        "\n",
        "# Defining the final word2vec model parameters\n",
        "vec_size = 300\n",
        "window_size = 15\n",
        "model_architecture = 1\n",
        "subsample = 1e-3\n",
        "\n",
        "# Creating the document level representation using the final word2vec model for each review in the training and testing splits\n",
        "w2v_model = Word2Vec(sentences = processed_reviews_train, size = vec_size, window = window_size, sg = model_architecture, sample = subsample, seed = 123)\n",
        "\n",
        "imdb_train = np.zeros([len(processed_reviews_train), vec_size])\n",
        "for i in tqdm.tqdm(range(len(processed_reviews_train))):\n",
        "  word_list = []\n",
        "  for word in processed_reviews_train[i]:\n",
        "    if word in w2v_model.wv.vocab:\n",
        "      word_list.append(word)\n",
        "      imdb_train[i] = np.mean(w2v_model.wv[word_list], axis = 0)\n",
        "\n",
        "imdb_test = np.zeros([len(processed_reviews_test), vec_size])\n",
        "for i in tqdm.tqdm(range(len(processed_reviews_test))):\n",
        "  word_list = []\n",
        "  for word in processed_reviews_test[i]:\n",
        "    if word in w2v_model.wv.vocab:\n",
        "      word_list.append(word)\n",
        "      imdb_test[i] = np.mean(w2v_model.wv[word_list], axis = 0)\n",
        "\n",
        "# Training a Naive Bayes model on the dataset\n",
        "imdb_nb = GaussianNB()\n",
        "imdb_nb_fit = imdb_nb.fit(imdb_train, imdb_train_y)\n",
        "\n",
        "# Training a Logistic Regression model on the dataset\n",
        "imdb_logreg = LogisticRegression(penalty = \"l1\", tol = 0.000001, C = 1, max_iter = 300, random_state = 123, solver = 'liblinear')\n",
        "imdb_logreg_fit = imdb_logreg.fit(imdb_train, imdb_train_y)\n",
        "\n",
        "# Training an SVM model on the dataset\n",
        "imdb_svm = SGDClassifier(alpha = 0.03125, random_state = 123)\n",
        "imdb_svm_fit = imdb_svm.fit(imdb_train, imdb_train_y)\n",
        "\n",
        "# Training a Random Forests model on the dataset\n",
        "imdb_rf = RandomForestClassifier(n_estimators = 300, min_samples_leaf = 2, max_features = 5, max_samples = 0.75, random_state = 123)\n",
        "imdb_rf_fit = imdb_rf.fit(imdb_train, imdb_train_y)\n",
        "\n",
        "# Using our models to obtain predictions and compute the F1-score\n",
        "imdb_nb_preds = imdb_nb_fit.predict(imdb_test)\n",
        "imdb_nb_f1 = f1_score(imdb_test_y, imdb_nb_preds)\n",
        "\n",
        "imdb_logreg_preds = imdb_logreg_fit.predict(imdb_test)\n",
        "imdb_logreg_f1 = f1_score(imdb_test_y, imdb_logreg_preds)\n",
        "\n",
        "imdb_svm_preds = imdb_svm_fit.predict(imdb_test)\n",
        "imdb_svm_f1 = f1_score(imdb_test_y, imdb_svm_preds)\n",
        "\n",
        "imdb_rf_preds = imdb_rf_fit.predict(imdb_test)\n",
        "imdb_rf_f1 = f1_score(imdb_test_y, imdb_rf_preds)\n",
        "\n",
        "# Outputting the F1 score for each classifier\n",
        "print(f\"Naive Bayes F1 score: {imdb_nb_f1}\")\n",
        "print(f\"Logistic Regression F1 score: {imdb_logreg_f1}\")\n",
        "print(f\"SVM F1 score: {imdb_svm_f1}\")\n",
        "print(f\"Random Forest F1 score: {imdb_rf_f1}\")"
      ],
      "metadata": {
        "id": "YmA-EZs3aJil"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}